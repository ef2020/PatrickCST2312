{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10 Dataframes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZLVuxZ87p1PE5ATnGgrwV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "48frmhZyk8Hr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOgniQhdQ6dY"
      },
      "source": [
        "### The information comes from different resources: \n",
        "* http://acme.byu.edu/\n",
        "* https://www.w3schools.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUs3f0-3I_pz"
      },
      "source": [
        "**NumPy is a powerful Python package for manipulating data with multi-dimensional vectors**\n",
        "\n",
        "Python's pandas\n",
        "library, built on NumPy, is designed specifically for data management and analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HCgg0EpIlTo"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGueMQvLMVmm"
      },
      "source": [
        "`NumPy` is used to work with arrays. The array object in NumPy is called ndarray. We can create a NumPy ndarray object by using the `array()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94UaPR5yMcPg"
      },
      "source": [
        "arr = np.array((1, 2, 3, 4, 5))\n",
        "arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NQMN9K4MhPo"
      },
      "source": [
        "#### Dimensions in Arrays\n",
        "A dimension in arrays is one level of array depth (nested arrays)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTb7G0SLMoWA"
      },
      "source": [
        "**0-D Arrays**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghbGdIGzMq_g"
      },
      "source": [
        "a_arr = np.array(42)\n",
        "a_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtdti3GvMxJw"
      },
      "source": [
        "**1-D Arrays**\n",
        "\n",
        "\n",
        "An array that has 0-D arrays as its elements is called uni-dimensional or 1-D array. These are the most common and basic arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBgo0tCYM4Ao"
      },
      "source": [
        "b_arr = np.array([1, 2, 3, 4, 5])\n",
        "b_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4cnyBOvM8AI"
      },
      "source": [
        "**2-D Arrays**\n",
        "An array that has 1-D arrays as its elements is called a 2-D array.\n",
        "\n",
        "These are often used to represent matrix or 2nd order tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1Tnp5r8M-wJ"
      },
      "source": [
        "c_arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "c_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GjPxG-uNH7H"
      },
      "source": [
        "**3-D arrays**\n",
        "An array that has 2-D arrays (matrices) as its elements is called 3-D array.\n",
        "\n",
        "These are often used to represent a 3rd order tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTti_buONLIa"
      },
      "source": [
        "d_arr = np.array([[[1, 2, 3], [4, 5, 6]], [[1, 2, 3], [4, 5, 6]]])\n",
        "d_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH_6GFxjNZZr"
      },
      "source": [
        "**Check Number of Dimensions?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFxtCXa9NdUY"
      },
      "source": [
        "print(a_arr.ndim)\n",
        "print(b_arr.ndim)\n",
        "print(c_arr.ndim)\n",
        "print(d_arr.ndim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-2YlKOmNuG_"
      },
      "source": [
        "### Basic Array Operations\n",
        "\n",
        "NumPy arrays behave differently with respect to the binary arithmetic operators + and * than Python\n",
        "lists do. For lists, + concatenates two lists and * replicates a list by a scalar amount (strings also\n",
        "behave this way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDbKUYrSN1Ey"
      },
      "source": [
        "# Addition concatenates lists together.\n",
        "[1, 2, 3] + [4, 5, 6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9cRJFOAN42v"
      },
      "source": [
        "# Mutliplication concatenates a list with itself a given number of times.\n",
        "[1, 2, 3] * 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK677euuN93x"
      },
      "source": [
        "`NumPy` arrays act like mathematical vectors and matrices: + and * perform component-wise\n",
        "addition or multiplication."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-JVSb0AOCRo"
      },
      "source": [
        "x = np.array([1, 2, 3])\n",
        "y = np.array([4, 5, 6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBuSfHMVyHzz"
      },
      "source": [
        "print(x.ndim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxrv1FIcOFwL"
      },
      "source": [
        "# Additionby a scalar acts on each element of the array.\n",
        "x + 10 # Add 10 to each entry of x."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ipkLTuzOLmp"
      },
      "source": [
        "# Multiplication by a scalar acts on each element of the array.\n",
        "x * 4 # Multiply each entry of x by 4."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E--enRTVOV4H"
      },
      "source": [
        "# Add two arrays together (component-wise).\n",
        "x + y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcIkM_lIOZnw"
      },
      "source": [
        "# Multiply two arrays together (component-wise).\n",
        "x * y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYP6KFG7OjQf"
      },
      "source": [
        "z = np.array([7,8,9,10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewLvmk1XOp6Q"
      },
      "source": [
        "x+z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4scZ4kYOuXY"
      },
      "source": [
        "y*z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YskjFEYsJag5"
      },
      "source": [
        "## Pandas Basics\n",
        "\n",
        "Pandas is a python library used primarily to analyze data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC66zwupJfsf"
      },
      "source": [
        "### Pandas Data Structures\n",
        "* Series\n",
        "* Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVGchu3EJifY"
      },
      "source": [
        "####Series\n",
        "\n",
        "A `Series` is a one-dimensional array that can hold any datatype. `Series` has an index that gives a label to each entry. An index generally is used to label the data.\n",
        "\n",
        "Typically a `Series` contains information about one feature of the data. For example, the data in a Series might show a class's grades on a test and the Index would indicate each student in the class. To initialize a Series, the first parameter is the data and the second is the index.\n",
        "\n",
        "https://www.w3resource.com/pandas/series/series.php\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ANny_T6JuJw"
      },
      "source": [
        "# Initialize Series of student grades\n",
        "math = pd.Series(np.random.randint(0,100,4), ['Mark', 'Barbara', 'Eleanor', 'David'])\n",
        "english = pd.Series(np.random.randint(0,100,5), ['Mark', 'Barbara', 'David', 'Greg', 'Lauren'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODFr_jCMKdNJ"
      },
      "source": [
        "math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suUgDSL_Kfyo"
      },
      "source": [
        "english"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KeWt229LgX8"
      },
      "source": [
        "# Series can be instantiated from dictionaries\n",
        "computers = {'Mark':45, 'Barbara':78, 'Sandy':93, 'Greg':89, 'Lauren':71}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNMR0AglL2ZX"
      },
      "source": [
        "computers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyqI4eJhL6xn"
      },
      "source": [
        "pd.Series(computers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQYPQijVKoKw"
      },
      "source": [
        "#### DataFrame\n",
        "\n",
        " A `DataFrame` is a collection of multiple `Series`. It can be thought of as a 2-dimensional array (table), where each row is a separate datapoint and\n",
        "each column is a feature of the data. The rows are labeled with an index (as in a `Series`) and the columns are labeled in the attribute columns.\n",
        "There are many different ways to initialize a DataFrame. One way to initialize a `DataFrame` is\n",
        "by passing in a dictionary as the data of the `DataFrame`. The keys of the dictionary will become the\n",
        "labels in columns and the values are the Series associated with the label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtFsmfZ1O2nw"
      },
      "source": [
        "# Create a DataFrame of student grades\n",
        "grades = pd.DataFrame({\"Math\": math, \"English\": english, \"Computers\":computers})\n",
        "grades"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKL9KQEsPJ4w"
      },
      "source": [
        "Notice that `pd.DataFrame` automatically lines up data from the three `Series` that have the same index. If the data only appears in one or two of the `Series` (not in all three), the entry for the missing `Series` is `NaN`.\n",
        "We can also initialize a `DataFrame` with a `NumPy` array. In this way, the data is passed in as a 2-dimensional `NumPy` array, while the column labels and index are passed in as parameters. The first column label goes with the first column of the array, the second with the second, etc. The same\n",
        "holds for the index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UgT0n2tPf3h"
      },
      "source": [
        "data = np.array([[80.0,76.0,78.0], [37.0,97.0,np.nan], [53.0, np.nan, np.nan], \n",
        "                 [np.nan, 48.0, 89.0], [np.nan, 68.0,\t71.0], [15.0,\t91.0,\t45.0], [np.nan, np.nan,\t93.0]])\n",
        "grades_from_arr = pd.DataFrame(data, columns = ['Math', 'English', 'Computers'], index =\n",
        " ['Barbara', 'David', 'Eleanor', 'Greg', 'Lauren', 'Mark', 'Sandy'])\n",
        "grades_from_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eVECp3ZQmYK"
      },
      "source": [
        "# View the columns\n",
        "grades_from_arr.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtvbBfpRQqun"
      },
      "source": [
        "# View the Index\n",
        "grades.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBvFRFjPQzth"
      },
      "source": [
        "### Data I/O\n",
        "\n",
        "The pandas library has functions that make importing and exporting data simple. The functions\n",
        "allow for a variety of file formats to be imported and exported, including CSV, Excel, HDF5, SQL,\n",
        "JSON, HTML, and pickle files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP4Fq6rcRNAB"
      },
      "source": [
        "**Methods**\n",
        "* `to_csv()`: Write the index and entries to a CSV file\n",
        "* `read_csv()`: Read a csv and convert into a DataFrame\n",
        "* `to_json()`: Convert the object to a JSON string\n",
        "* `to_pickle()`: Serialize the object and store it in an external file\n",
        "* `to_sql()`: Write the object data to an open SQL database\n",
        "* `read_html()`: Read a table in an html page and convert to a DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyIAf8K9Rs9B"
      },
      "source": [
        "###Data Manipulation\n",
        "\n",
        "**Accessing Data**\n",
        "\n",
        "Accessing `Series` and `DataFrame` objects using `loc` and `iloc` indexers indexing operations is efficient. \n",
        "\n",
        "Bracket indexing has to check many cases before it can\n",
        "determine how to slice the data structure. \n",
        "\n",
        "Using `loc/iloc` explicitly, bypasses the extra checks. \n",
        "\n",
        "The `loc` index selects rows and columns based on their labels, while `iloc` selects them based on their integer position. When using these indexers, the first and second arguments refer to the rows and\n",
        "columns, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqqhZRtySYyZ"
      },
      "source": [
        "grades"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdxmIyCDSaS-"
      },
      "source": [
        "# Use loc to select the Math scores of David and Greg\n",
        "grades.loc[['David', 'Greg'],'Math']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzKpx1XOShfv"
      },
      "source": [
        "# Use iloc to select the Math scores of David and Greg\n",
        "grades.iloc[[1,3], 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1weCNw_oSn__"
      },
      "source": [
        "An entire column of a `DataFrame` can be accessed using simple square brackets and the name of the column. In addition, to create a new column or reset the values of an entire column, simply\n",
        "call this column in the same fashion and set the value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgFv_sIpSnVR"
      },
      "source": [
        "# Set new History column with array of random values\n",
        "# !!! In the below statment we MUST generate values for every index. \n",
        "# WHY?\n",
        "grades['History'] = np.random.randint(0,100,7)\n",
        "grades['History']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_o1i1ytTFLO"
      },
      "source": [
        "# Reset the column such that everyone has a 100\n",
        "grades['History'] = 100.0\n",
        "grades"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WKBiU8YTLKw"
      },
      "source": [
        "Often datasets can be very large and difficult to visualize. `Pandas` offers various methods to\n",
        "make the data easier to visualize. The methods head and tail will show the first or last n data\n",
        "points, respectively, where n defaults to 5. The method sample will draw n random entries of the\n",
        "dataset, where n defaults to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z40EE43CTRgX"
      },
      "source": [
        "# Use head to see the first n rows\n",
        "grades.head(n=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dECudx2PTTbv"
      },
      "source": [
        "# Use head to see the first n rows\n",
        "grades.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sndYmWiyTYaf"
      },
      "source": [
        "# Use sample to sample a random entry\n",
        "grades.sample()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtNBB2APTaDY"
      },
      "source": [
        "# Use sample to sample a random entry\n",
        "grades.tail(n=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-311ZD9TeNo"
      },
      "source": [
        "It may also be useful to re-order the columns or rows or sort according to a given column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6aT8HEtTgZh"
      },
      "source": [
        "# Re-order columns\n",
        "new_grades = grades.reindex(columns=['English','Math','History','Computers'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fARYpzfkTrLo"
      },
      "source": [
        "# We did not reassigne the resulting dataframe to a new dataframe\n",
        "# the inital order stays intact \n",
        "new_grades"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqnD0am2T6pP"
      },
      "source": [
        "# Sort descending according to Math grades\n",
        "grades.sort_values('Math', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmRDxowhUA8T"
      },
      "source": [
        "Other methods used for manipulating `DataFrame` and `Series` `pandas` structures:\n",
        "* `append()`: Concatenate two or more Series.\n",
        "* `drop()`: Remove the entries with the speci\u001ced label or labels\n",
        "* `drop_duplicates()`: Remove duplicate values\n",
        "* `dropna()`: Drop null entries\n",
        "* `fillna()`: Replace null entries with a speci\u001ced value or strategy\n",
        "* `reindex()`: Replace the index\n",
        "* `sample()`: Draw a random entry\n",
        "* `shift()`: Shift the index\n",
        "* `unique()`: Return unique values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLq23NzwUXlZ"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Create a dataframe, given the table below: \n",
        "\n",
        "[https://github.com/ef2020/PatrickCST2312/blob/main/csv_to_dataframe.jpg](https://github.com/ef2020/PatrickCST2312/blob/main/csv_to_dataframe.jpg)\n",
        "\n",
        "1. Try different methods for creating the DataFrame (if the data is not available use the NaN code): \n",
        "    * Create five `Pandas Series` and combine them into a data frame.\n",
        "    * Create a dictionary and then a dataframe given the dictionay.\n",
        "    * Create a CSV file, upload is locally and get the data from this file. \n",
        "\n",
        "2. Reindex the columns such that age becomes the last column while the rest of the columns maintain the same ordering.\n",
        "2. Sort the DataFrame in descending order based on the age.\n",
        "3. Reset all values in the 'preTestScore' column to 0.0.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku3lvBpz6tfG"
      },
      "source": [
        "data = np.array([[\"Jason\", \"Miller\", 42, 4, 25000], [\"Molly\", \"Jacobson\", 52, 24, 94000], \n",
        "                 [\"Tina\", np.nan, 36, 31, 57]])\n",
        "dfarr = pd.DataFrame(data, columns = ['first_name', 'last_name', 'age', 'preTestScore', 'postTestScore'], index =\n",
        " [0, 1, 2])\n",
        "dfarr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94vC98qoXT-B"
      },
      "source": [
        "### Solutoin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixw2VB-Ya9n3"
      },
      "source": [
        "**How To Drop a Single Column from a Dataframe?**\n",
        "\n",
        "To drop a single column from `pandas dataframe`, we need to provide the name of the column to be dropped as a list as an argument to `drop()` function. \n",
        "\n",
        "To specify we want to drop column, we need to provide `axis=1` as another argument to drop function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BayNVsZMbTlp"
      },
      "source": [
        "dfcsv.drop(\"Unnamed: 0\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNmViTCH5qEi"
      },
      "source": [
        "dfcsv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKw7Wb5pbrT1"
      },
      "source": [
        "dfcsv = dfcsv.drop(\"Unnamed: 0\", axis=1)\n",
        "dfcsv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_EJ8GSLb2PE"
      },
      "source": [
        "**How To Drop Rows from a Dataframe?**\n",
        "\n",
        "`Pandas` make it easy to drop rows of a dataframe as well. We can use the same `drop()` function to drop rows in `Pandas`.\n",
        "\n",
        "To drop one or more rows from a `Pandas` dataframe, we need to specify the row indexes that need to be dropped and `axis=0` argument. Here, `axis=0` argument specifies we want to drop rows instead of dropping columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTyIVEi1cEcW"
      },
      "source": [
        "new_dfcsv.drop([2, 3], axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udpyx8eMcLts"
      },
      "source": [
        "grades"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqgAmCLmcNsm"
      },
      "source": [
        "grades.drop([\"David\", \"Sandy\"], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htvfL0FW6JQV"
      },
      "source": [
        "grades"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBvYNhjE6L1I"
      },
      "source": [
        "grades.drop([0, 2], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlZVWq_kdHOE"
      },
      "source": [
        "### Dealing with Missing Data\n",
        "\n",
        "Missing data is a ubiquitous problem in data science. Fortunately, `pandas` is particularly well-suited\n",
        "to handling missing and anomalous data. As we have already seen, the `pandas` default for a missing\n",
        "value is `NaN`. In basic arithmetic operations, if one of the operands is `NaN`, then the output is also\n",
        "`NaN`. The following example illustrates this concept:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bC_rXWjdTdh"
      },
      "source": [
        "x = pd.Series(np.arange(5))\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRMn0Au3dZfO"
      },
      "source": [
        "y = pd.Series(np.random.randn(5))\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH8GhqGgdanW"
      },
      "source": [
        "x.iloc[3] = np.nan\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP5zqyZZdf7F"
      },
      "source": [
        "x+y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duTfy_dldmC2"
      },
      "source": [
        "If we are not interested in the missing values, we can simply drop them from the data altogether:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ATnO7CddolS"
      },
      "source": [
        "z = (x + y).dropna()\n",
        "z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IYkkL7mdrKn"
      },
      "source": [
        "This is not always the desired behavior, however. It may well be the case that missing data\n",
        "actually corresponds to some default value, such as zero. In this case, we can replace all instances of\n",
        "NaN with a specified value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5tplM17dta_"
      },
      "source": [
        "# fill missing data with 0, add\n",
        "x.fillna(0) + y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnG63am-dyZF"
      },
      "source": [
        "Other functions, such as `sum()` and `mean()` ignore `NaN` values in the computation. When\n",
        "dealing with missing data, make sure you are aware of the behavior of the `pandas` functions you are\n",
        "using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s-tdv9vmNHJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVEvWk42lfi4"
      },
      "source": [
        "## Selecting a subset of the columns\n",
        "\n",
        "In a dataframe, we can specify the column(s) that we want to keep, and get back another dataframe with just the subset of the columns that we want to keep."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WqqmxdVkotS"
      },
      "source": [
        "! curl https://raw.githubusercontent.com/ef2020/PatrickCST2312/master/iris.csv -o iris.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4foBJGnkuBR"
      },
      "source": [
        "# famous machine learning data set: https://archive.ics.uci.edu/ml/datasets/iris\n",
        "iris = pd.read_csv(\"iris.csv\")\n",
        "iris"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11LmXyeimunZ"
      },
      "source": [
        "iris.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrv2Y2CFic4c"
      },
      "source": [
        "iris.iloc[149]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt9JLWqBi2jj"
      },
      "source": [
        "iris[['variety']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqvxZiWOlbGT"
      },
      "source": [
        "iris  [[\"sepal.length\",\t\"sepal.width\", \"variety\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evH1T7ydlx7Q"
      },
      "source": [
        "## Selecting rows\n",
        "\n",
        "To select rows, we can use the following approach, where we generate a list of boolean values, one for each row of the dataframe, and then we use the list to select which of the rows of the dataframe we want to keep\"\n",
        "\n",
        "Decision tree: https://www.researchgate.net/figure/Decision-tree-for-Iris-dataset_fig1_293194222"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9Uxy9ENmbfx"
      },
      "source": [
        "# check out the condition for petal width <= 0.6\n",
        "iris[\"petal.width\"]<=0.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNbm0QXulysw"
      },
      "source": [
        "# create the condition petal_width_l06 where petal width <= 0.6\n",
        "petal_width_l06 = (iris[\"petal.width\"]<=0.6 )\n",
        "petal_width_l06"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhBk3axknYjU"
      },
      "source": [
        "# apply the petal_width_l06 condition to the iris data set\n",
        "len(iris[petal_width_l06])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtqwN5ZZn9dz"
      },
      "source": [
        "pw_g06_pw_le17_plle49 = ((iris[\"petal.width\"]>0.6 ) \n",
        "                      & (iris[\"petal.width\"]<=1.7 )\n",
        "                      & (iris[\"petal.length\"]<=4.9 ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO3IKFvKokyY"
      },
      "source": [
        "len(iris[pw_g06_pw_le17_plle49])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8pFEuL8qc7h"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Given the decision tree, output the rows with the Iris-virginica data points (you might have spurious data points or missing data points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnNQMktaq4BC"
      },
      "source": [
        "## New Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzO0bgz-u9rw"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/ef2020/PatrickCST2312/master/HairEyeColor.csv -o  HairEyeColor.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip70GByuwE9J"
      },
      "source": [
        "hec = pd.read_csv(\"HairEyeColor.csv\")\n",
        "hec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr7vz9Ahqnog"
      },
      "source": [
        "hec = hec.drop(\"Unnamed: 0\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la41uYMBQFP_"
      },
      "source": [
        "hec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUd0vxgGqTed"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "* Output the records for females with red hair.\n",
        "* Output the records for blondes with blue eyes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-verzyDqEww"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGVRZ-v8nSjS"
      },
      "source": [
        "# your solution here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhZjOOvGosMI"
      },
      "source": [
        "## Pivot Tables\n",
        "\n",
        "[Pivot tables](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html) is one of the most commonly used exploratory tools, and in Pandas they are extremely flexible. \n",
        "\n",
        "https://rdrr.io/r/datasets/HairEyeColor.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbHr1hGDwMrp"
      },
      "source": [
        "hec.pivot_table(values=\"Freq\", index=[\"Hair\", \"Eye\"], columns=\"Sex\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e7hV-DmrPUA"
      },
      "source": [
        "hec.pivot_table(values=\"Freq\", index=\"Sex\", columns=[\"Hair\", \"Eye\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOUbx-IbrYr3"
      },
      "source": [
        "hec.pivot_table(values=\"Freq\", index=[\"Hair\", \"Sex\"], columns=\"Eye\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb2-CNoKw_Se"
      },
      "source": [
        "Unlike `HairEyeColor`, many data sets have more than one entry in the data for each grouping\n",
        "(for example, if there were two or more rows in the original data for females with blond hair and blue\n",
        "eyes). To construct a pivot table, data of similar groups must be aggregated together in some way.\n",
        "By default entries are aggregated by averaging the non-null values. Other options include taking the\n",
        "min, max, standard deviation, or just counting the number of occurrences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylOiIN4vn8O6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT0z8VawnotF"
      },
      "source": [
        "## Patrick, then I was running a lot of examples life using the Titanic data set and the following resources with examples: \n",
        "\n",
        "* https://regenerativetoday.com/use-of-pivot-table-in-pandas/\n",
        "* https://www.w3resource.com/python-exercises/pandas/excel/pandas-pivot-titanic-exercise-3.php\n",
        "* https://www.kaggle.com/kamilpolak/tutorial-how-to-use-pivot-table-in-pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eNox2IHoKDv"
      },
      "source": [
        "## Patrick, afterwards, I was discussing the NYC Open Data platform (https://opendata.cityofnewyork.us/) and was choosing data sets from these platform to review the material from the course: \n",
        "* upload the dataset\n",
        "* create a dataframe\n",
        "* analyze dataframe (data types, attribute names, missing values)\n",
        "* select particular columns\n",
        "* seecct particular records (using if statements, regular expressions, etc.).\n",
        "\n",
        "Several data sets that I found interesting and useful: \n",
        "* New York City Leading Causes of Death (https://data.cityofnewyork.us/Health/New-York-City-Leading-Causes-of-Death/jb7j-dtam)\n",
        "* DOHMH New York City Restaurant Inspection Results (https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j)\n",
        "* Motor Vehicle Collisions (https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95)"
      ]
    }
  ]
}